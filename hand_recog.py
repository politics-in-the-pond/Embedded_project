from sys import stdout
import time
import sys
import matplotlib.pyplot as plt
import mediapipe as mp
import numpy as np
import time
import cv2

# mp.solutions.hands í´ë˜ìŠ¤ë¥¼ ì´ˆê¸°í™”í•˜ê³  mp.solutions.handsë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.Hands()ëŠ” ì ì ˆí•œ ì¸ìˆ˜ë¡œ ì‘ë™í•˜ë©° íƒì§€ëœ ëœë“œë§ˆí¬ë¥¼ ì‹œê°í™”í•˜ëŠ” ë° í•„ìš”í•œ mp.solutions.drawing_utils í´ë˜ìŠ¤ë„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤
#
# static_image_mode ì¸ìˆ˜ë¥¼ Trueë¡œ ì„¤ì •í•˜ë©´ ì´ë¯¸ì§€ì— ì‚¬ìš©í•  ìˆ˜ ìˆê³ , static_image_modeë¥¼ Falseë¡œ ì„¤ì •í•˜ë©´ ë¹„ë””ì˜¤ì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤


# Initialize the mediapipe hands class.
# ê¸°ë³¸ì„¸íŒ…
# mediapipe í´ë˜ìŠ¤ ì´ˆê¸°í™”
mp_hands = mp.solutions.hands

# Set up the Hands functions for images and videos.
hands = mp_hands.Hands(static_image_mode=True,
                       max_num_hands=2, min_detection_confidence=0.5)
hands_videos = mp_hands.Hands(
    static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5)

# Initialize the mediapipe drawing class.
mp_drawing = mp.solutions.drawing_utils


# ì´ ë‹¨ê³„ì—ì„œëŠ” ì´ë¯¸ì§€/í”„ë ˆì„ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  Media pipeì—ì„œ ì œê³µí•˜ëŠ” ì†”ë£¨ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€/í”„ë ˆì„ì˜
# ì†ì—ì„œ ëœë“œë§ˆí¬ ê²€ì¶œì„ ìˆ˜í–‰í•˜ê³  ì´ë¯¸ì§€ì˜ ê° ì†ì— ëŒ€í•´ 21ê°œì˜ 3D ëœë“œë§ˆí¬ë¥¼ ì–»ëŠ” detect Hands Landmarks() ê¸°ëŠ¥ì„ ë§Œë“­ë‹ˆë‹¤.
# í•¨ìˆ˜ëŠ” ì „ë‹¬ëœ ì¸ìˆ˜ì— ë”°ë¼ ê²°ê³¼ë¥¼ í‘œì‹œí•˜ê±°ë‚˜ ë°˜í™˜í•©ë‹ˆë‹¤.

def detectHandsLandmarks(image, hands, draw=True, display=True):
    '''

        image: ëœë“œë§ˆí¬ë¥¼ ê°ì§€í•´ì•¼ í•˜ëŠ” ëˆˆì— ë„ëŠ” ì†ì´ ìˆëŠ” ì…ë ¥ ì´ë¯¸ì§€.
        hands: í•¸ë“œ ëœë“œë§ˆí¬ ê°ì§€ë¥¼ ìˆ˜í–‰í•˜ëŠ” ë° í•„ìš”í•œ Hands ê¸°ëŠ¥.
        draw: í•¨ìˆ˜ê°€ trueë¡œ ì„¤ì •ëœ ê²½ìš° ì¶œë ¥ ì´ë¯¸ì§€ì— í•¸ì¦ˆ ëœë“œë§ˆí¬ë¥¼ ê·¸ë¦¬ëŠ” ë¶€ìš¸ ê°’ì…ë‹ˆë‹¤.
        display: í•¨ìˆ˜ê°€ trueë¡œ ì„¤ì •ëœ ê²½ìš° ì›ë˜ ì…ë ¥ ì´ë¯¸ì§€ì™€ ì¶œë ¥ì„ í‘œì‹œí•˜ëŠ” ë¶€ìš¸ ê°’
        ì§€ì •ëœ ê²½ìš° ì•„ë¬´ê²ƒë„ ë°˜í™˜í•˜ì§€ ì•ŠëŠ” ì† ëœë“œë§ˆí¬ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€.
    return:
        output_image: ì§€ì •ëœ ê²½ìš° íƒì§€ëœ ì† ëœë“œë§ˆí¬ê°€ ê·¸ë ¤ì§„ ì…ë ¥ ì´ë¯¸ì§€ì˜ ë³µì‚¬ë³¸ì…ë‹ˆë‹¤.
        ê²°ê³¼: ì…ë ¥ ì˜ìƒì—ì„œ ì† ëœë“œë§ˆí¬ ê²€ì¶œì˜ ì¶œë ¥.
    '''

    # Create a copy of the input image to draw landmarks on.
    # ë³µì‚¬ë³¸ ë§Œë“¤ê¸°
    output_image = image.copy()

    # Convert the image from BGR into RGB format.
    # BGR - RGB
    imgRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Perform the Hands Landmarks Detection.
    results = hands.process(imgRGB)

    # Check if landmarks are found and are specified to be drawn.
    if results.multi_hand_landmarks and draw:

        # Iterate over the found hands.
        for hand_landmarks in results.multi_hand_landmarks:

            # Draw the hand landmarks on the copy of the input image.
            # í•¸ë“œ ëœë“œë§Œí¬ ê·¸ë¦¬ê¸°
            mp_drawing.draw_landmarks(
                image=output_image, landmark_list=hand_landmarks,
                connections=mp_hands.HAND_CONNECTIONS,
                landmark_drawing_spec=mp_drawing.DrawingSpec(color=(255, 255, 255),
                                                             thickness=2, circle_radius=2),
                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0),
                                                               thickness=2, circle_radius=2))

    # Check if the original input image and the output image are specified to be displayed.
    if display:

        # Display the original input image and the output image.
        plt.figure(figsize=[15, 15])
        plt.subplot(121)
        plt.imshow(image[:, :, ::-1])
        plt.title("Original Image")
        plt.axis('off')
        plt.subplot(122)
        plt.imshow(output_image[:, :, ::-1])
        plt.title("Output")
        plt.axis('off')

    # Otherwise
    else:

        # Return the output image and results of hands landmarks detection.
        return output_image, results


# ì´ì œ ì´ ë‹¨ê³„ì—ì„œëŠ” detect Hands Landmarks() ê¸°ëŠ¥ì— ì˜í•´ ë°˜í™˜ë˜ëŠ” ëœë“œë§ˆí¬ ê°ì§€ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¤ê³  ëœë“œë§ˆí¬ë¥¼ í™œìš©í•˜ì—¬ ì´ë¯¸ì§€/í”„ë ˆì„ì˜ ê° ì†ì˜ ì†ê°€ë½ ìˆ˜ë¥¼ ì„¸ê³ 
# ì´ë¯¸ì§€ì— ìˆëŠ” ê° ì†ê°€ë½ì˜ ìˆ˜ì™€ ìƒíƒœë¥¼ ë°˜í™˜í•˜ëŠ” ê¸°ëŠ¥ ì¹´ìš´íŠ¸()ë¥¼ ë§Œë“­ë‹ˆë‹¤.
# ì†ê°€ë½ì˜ ëê³¼ ì¤‘ê°„ë§ˆë””ë¥¼ ë¹„êµí•œë‹¤ Yì˜ ì¢Œí‘œê°€ ì•„ë˜ë¡œ ë‚´ë ¤ê°ˆìˆ˜ë¡œ ì»¤ì§€ë‹ˆê¹ ì†ê°€ë½ì´ í´ì§€ëŠ”ê²½ìš°
# FINGER_TIP =ì†ê°€ë½ ëì´ FINGER_PIP ì†ê°€ë½ ì¤‘ê°„ë§ˆë””ë³´ë‹¤ ë†’ì´ ìˆìœ¼ë¯€ë¡œ Yì¢Œí‘œëŠ” 0ì— ê°€ê¹ê¸°ë•Œë¬¸ì—
# ë” ì‘ì€ ê°’ì„ ê°€ì§„ë‹¤

# ê·¸ëŸ¬ë‚˜ ì—„ì§€ì†ê°€ë½ì˜ ê²½ìš° TUMB_TIP ëœë“œë§ˆí¬ì™€ TUMB_MCP ëœë“œë§ˆí¬ì˜ x ì¢Œí‘œë¥¼ ë¹„êµí•´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ì‹œë‚˜ë¦¬ì˜¤ê°€ ì¡°ê¸ˆ ë‹¤ë¥¼ ê²ƒì´ê³ ,
# ì†ì´ ì™¼ìª½ì¸ì§€ ì˜¤ë¥¸ìª½ì¸ì§€ì— ë”°ë¼ ì¡°ê±´ì´ ë‹¬ë¼ì§ˆ ê²ƒì´ë‹¤.

# ì˜¤ë¥¸ì†ì˜ ê²½ìš° ì˜¤ë¥¸ì†ì—„ì§€ì˜ ëì´ ì˜¤ë¥¸ì† ë§ˆë”” ëë³´ë‹¤ ë‚®ì€ X ì˜ ê°’
# ê·¸ëŸ¬ë‚˜ ì™¼ì†ì˜ê²½ìš° ì™¼ì† ì—„ì§€ì˜ ëì´ ì™¼ì† ë§ˆë”” ëë³´ë‹¤ ë†’ì€ x ì˜ ê°’


def countFingers(image, results, draw=True, display=True):
    '''
    This function will count the number of fingers up for each hand in the image.
    Args:
        image:   The image of the hands on which the fingers counting is required to be performed.
        results: The output of the hands landmarks detection performed on the image of the hands.
        draw:    A boolean value that is if set to true the function writes the total count of fingers of the hands on the
                output image.
        display: A boolean value that is if set to true the function displays the resultant image and returns nothing.
    Returns:
        output_image:     A copy of the input image with the fingers count written, if it was specified.
        fingers_statuses: A dictionary containing the status (i.e., open or close) of each finger of both hands.
        count:            A dictionary containing the count of the fingers that are up, of both hands.
    '''

    # Get the height and width of the input image.
    height, width, _ = image.shape

    # Create a copy of the input image to write the count of fingers on.
    output_image = image.copy()

    # Initialize a dictionary to store the count of fingers of both hands.
    count = {'RIGHT': 0, 'LEFT': 0}

    # Store the indexes of the tips landmarks of each finger of a hand in a list.
    # ì—„ì§€ ì†ê°€ë½ì„ ì œì™¸í•œ ì¸ë±ìŠ¤ ì„¤ì •
    # ì†ê°€ë½ë  idx ì €ì¥
    fingers_tips_ids = [mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_TIP,
                        mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.PINKY_TIP]

    # Initialize a dictionary to store the status (i.e., True for open and False for close) of each finger of both hands.
    # ì†ê°€ë½ ì—´ë¦¬ë©´ trueë¡œ
    fingers_statuses = {'RIGHT_THUMB': False, 'RIGHT_INDEX': False, 'RIGHT_MIDDLE': False, 'RIGHT_RING': False,
                        'RIGHT_PINKY': False, 'LEFT_THUMB': False, 'LEFT_INDEX': False, 'LEFT_MIDDLE': False,
                        'LEFT_RING': False, 'LEFT_PINKY': False}

    # Iterate over the found hands in the image.
    for hand_index, hand_info in enumerate(results.multi_handedness):

        # Retrieve the label of the found hand.
        # ì† ê²€ìƒ‰
        hand_label = hand_info.classification[0].label

        # Retrieve the landmarks of the found hand.
        hand_landmarks = results.multi_hand_landmarks[hand_index]

        # Iterate over the indexes of the tips landmarks of each finger of the hand.
        for tip_index in fingers_tips_ids:

            # Retrieve the label (i.e., index, middle, etc.) of the finger on which we are iterating upon.
            finger_name = tip_index.name.split("_")[0]

            # Check if the finger is up by comparing the y-coordinates of the tip and pip landmarks.
            # ì†ê°€ë½ì´ í´ì¡ŒëŠ”ì§€ í™•ì¸
            if (hand_landmarks.landmark[tip_index].y < hand_landmarks.landmark[tip_index - 2].y):

                # Update the status of the finger in the dictionary to true.
                # ì†ê°€ë½ì´ í´ì¹œìƒíƒœì´ë¯€ë¡œ trueë¡œ ë°”ê¾¸ì
                fingers_statuses[hand_label.upper()+"_"+finger_name] = True

                # Increment the count of the fingers up of the hand by 1.
                # ê°œìˆ˜ ëŠ˜ë ¤ ëŠ˜ë ¤
                count[hand_label.upper()] += 1

        # Retrieve the y-coordinates of the tip and mcp landmarks of the thumb of the hand.
        # ì—„ì§€ì†ê°€ë½ ê²€ìƒ‰
        thumb_tip_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x
        thumb_mcp_x = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP - 2].x

        # Check if the thumb is up by comparing the hand label and the x-coordinates of the retrieved landmarks.
        # ì™¼ì†ê³¼ ì˜¤ë¥¸ì†ì€ ë”°ë¡œ ë”°ë¡œ êµ¬ë³„í•´ì„œ ì ìš©í•´ì•¼í•¨
        if (hand_label == 'Right' and (thumb_tip_x < thumb_mcp_x)) or (hand_label == 'Left' and (thumb_tip_x > thumb_mcp_x)):

            # Update the status of the thumb in the dictionary to true.
            # ì†ê°€ë½ì´ í´ì¹œìƒíƒœì´ë¯€ë¡œ trueë¡œ ë°”ê¾¸ì
            fingers_statuses[hand_label.upper()+"_THUMB"] = True

            # Increment the count of the fingers up of the hand by 1.
            # ê°œìˆ˜ ëŠ˜ë ¤ ëŠ˜ë ¤
            count[hand_label.upper()] += 1

    # Check if the total count of the fingers of both hands are specified to be written on the output image.
    if draw:

        # Write the total count of the fingers of both hands on the output image.
        # ì¶œë ¥ ì´ë¯¸ì§€ì— ì–‘ì†ì˜ ì´ ì†ê°€ë½ ìˆ˜ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
        cv2.putText(output_image, " Total Fingers: ", (10, 25),
                    cv2.FONT_HERSHEY_COMPLEX, 1, (20, 255, 155), 2)
        cv2.putText(output_image, str(sum(count.values())), (width//2-150, 240), cv2.FONT_HERSHEY_SIMPLEX,
                    8.9, (20, 255, 155), 10, 10)

    # Check if the output image is specified to be displayed.
    if display:

        # Display the output image.
        plt.figure(figsize=[10, 10])
        plt.imshow(output_image[:, :, ::-1])
        plt.title("Output Image")
        plt.axis('off')

    # Otherwise
    else:

        # Return the output image, the status of each finger and the count of the fingers up of both hands.
        return output_image, fingers_statuses, count


# ì´ ë‹¨ê³„ì—ì„œ ê¸°ëŠ¥ ì¹´ìš´íŠ¸ Fingers()ì—ì„œ ì¶œë ¥ëœ ì†ê°€ë½ì˜ ìƒíƒœ(ì¦‰, ìœ„ ë˜ëŠ” ì•„ë˜)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ì†ì˜ ì œìŠ¤ì²˜ë¥¼ ê²°ì •í•˜ëŠ” ê¸°ëŠ¥ recognizeGestures()ë¥¼ ë§Œë“¤ ê²ƒì´ë‹¤. ì´ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ì€ ì†ë™ì‘ì„ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#
# V Hand Gesture(V ì† ì œìŠ¤ì²˜) âœŒ1900(ì˜ˆ: ê²€ì§€ì™€ ê°€ìš´ë° ì†ê°€ë½ë§Œ ìœ„ë¡œ)
# ìŠ¤íŒŒì´ë”ë§¨ ì† ì œìŠ¤ì²˜ ğŸ¤Ÿ(ì˜ˆ: ì—„ì§€, ê²€ì§€, ì†ê°€ë½ ìœ„ë¡œ)
# HIGH-FIVE ì†ë™ì‘ âœ‹ (ì¦‰, ë‹¤ì„¯ ì†ê°€ë½ ëª¨ë‘ ìœ„ë¡œ)
# ë‹¨ìˆœì„±ì„ ìœ„í•´, ìš°ë¦¬ëŠ” ì´ê²ƒì„ ì„¸ ê°€ì§€ ì†ì§“ìœ¼ë¡œë§Œ ì œí•œí•˜ê³  ìˆë‹¤. ê·¸ëŸ¬ë‚˜ ì›í•˜ëŠ” ê²½ìš° ì´ ê¸°ëŠ¥ì„ ì‰½ê²Œ í™•ì¥í•˜ì—¬ ì¡°ê±´ë¬¸ì„ ì¶”ê°€í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ ë” ë§ì€ ì œìŠ¤ì²˜ë¥¼ ì‹ë³„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.


def recognizeGestures(image, fingers_statuses, count, draw=True, display=True):
    '''
    This function will determine the gesture of the left and right hand in the image.
    Args:
        image:            The image of the hands on which the hand gesture recognition is required to be performed.
        fingers_statuses: A dictionary containing the status (i.e., open or close) of each finger of both hands. 
        count:            A dictionary containing the count of the fingers that are up, of both hands.
        draw:             A boolean value that is if set to true the function writes the gestures of the hands on the
                        output image, after recognition.
        display:          A boolean value that is if set to true the function displays the resultant image and 
                        returns nothing.
    Returns:
        output_image:   A copy of the input image with the left and right hand recognized gestures written if it was 
                        specified.
        hands_gestures: A dictionary containing the recognized gestures of the right and left hand.
    '''

    '''
     fingers_statuses = {'RIGHT_THUMB': False, 'RIGHT_INDEX': False, 'RIGHT_MIDDLE': False, 'RIGHT_RING': False,
                        'RIGHT_PINKY': False, 'LEFT_THUMB': False, 'LEFT_INDEX': False, 'LEFT_MIDDLE': False,
                        'LEFT_RING': False, 'LEFT_PINKY': False}
    '''
    # Create a copy of the input image.
    output_image = image.copy()

    # Store the labels of both hands in a list.
    hands_labels = ['RIGHT', 'LEFT']

    # Initialize a dictionary to store the gestures of both hands in the image.
    hands_gestures = {'RIGHT': "UNKNOWN", 'LEFT': "UNKNOWN"}

    # Iterate over the left and right hand.
    for hand_index, hand_label in enumerate(hands_labels):

        # Initialize a variable to store the color we will use to write the hands gestures on the image.
        # Initially it is red which represents that the gesture is not recognized.
        color = (0, 0, 255)
        # ------------------------------------ì—¬ê¸°ì„œ ì† ë™ì‘ ì²´í¬í•˜ê¸°  ------------------------------------

        # Check if the person is making the 'V' gesture with the hand.
        ####################################################################################################################

        # Check if the number of fingers up is 2 and the fingers that are up, are the index and the middle finger.
        if count[hand_label] == 2 and fingers_statuses[hand_label+'_MIDDLE'] and fingers_statuses[hand_label+'_INDEX']:

            # Update the gesture value of the hand that we are iterating upon to V SIGN.
            # hand_index = 0 ì¼ë–„ëŠ” ì˜¤ë¥¸ì† hand_index =1 ì¼ë–„ëŠ” ì™¼ì† ì¡°ê±´ ì£¼ê¸°

            # ì˜¤ë¥¸ì†
            if hand_index == 0:
                hands_gestures[hand_label] = "RIGHT_V_SIGN"
            # ì™¼ì†
            elif hand_index == 1:
                hands_gestures[hand_label] = "LEFT_V_SIGN"

            # Update the color value to green.
            color = (0, 255, 0)

        ####################################################################################################################

        # Check if the person is making the 'SPIDERMAN' gesture with the hand.
        ##########################################################################################################################################################

        # Check if the number of fingers up is 3 and the fingers that are up, are the thumb, index and the pinky finger.
        elif count[hand_label] == 3 and fingers_statuses[hand_label+'_THUMB'] and fingers_statuses[hand_label+'_INDEX'] and fingers_statuses[hand_label+'_PINKY']:

            # Update the gesture value of the hand that we are iterating upon to SPIDERMAN SIGN.
            #hands_gestures[hand_label] = "SPIDERMAN SIGN"

            # ì˜¤ë¥¸ì†
            if hand_index == 0:
                hands_gestures[hand_label] = "RIGHT_SPIDERMAN_SIGN"
            # ì™¼ì†
            elif hand_index == 1:
                hands_gestures[hand_label] = "LEFT_SPIDERMAN_SIGN"

            # Update the color value to green.
            color = (0, 255, 0)

        ##########################################################################################################################################################

        # Check if the person is making the 'HIGH-FIVE' gesture with the hand.
        ####################################################################################################################

        # í•˜ì´íŒŒì´ë¸Œ ì²´í¬

        # Check if the number of fingers up is 5, which means that all the fingers are up.
        elif count[hand_label] == 5:

            # Update the gesture value of the hand that we are iterating upon to HIGH-FIVE SIGN.
            if hand_index == 1:
                hands_gestures[hand_label] = "RIGHT_HIGH_FIVE_SIGN"
            elif hand_index == 0:
                hands_gestures[hand_label] = "LEFT_HIGH_FIVE_SIGN"

            # Update the color value to green.
            color = (0, 255, 0)

        ####################################################################################################################

        # ì£¼ë¨¹ ì¥”ê±° ì²´í¬

        elif count[hand_label] == 0:
            #hands_gestures[hand_label] = "STOP"
            if hand_index == 0:
                hands_gestures[hand_label] = "RIGHT_STOP_SIGN"
            elif hand_index == 1:
                hands_gestures[hand_label] = "LEFT_STOP_SIGN"

            # Update the color value to green.
            color = (0, 255, 0)

        ####################################################################################################################

        # Check if the hands gestures are specified to be written.
        if draw:

            # Write the hand gesture on the output image.
            cv2.putText(output_image, hand_label + ': ' + hands_gestures[hand_label], (10, (hand_index+1) * 60),
                        cv2.FONT_HERSHEY_PLAIN, 4, color, 5)

    # Check if the output image is specified to be displayed.
    if display:

        # Display the output image.
        plt.figure(figsize=[10, 10])
        plt.imshow(output_image[:, :, ::-1])
        plt.title("Output Image")
        plt.axis('off')

    # Otherwise
    else:

        # Return the output image and the gestures of the both hands.
        return output_image, hands_gestures


# Initialize the VideoCapture object to read from the webcam.
camera_video = cv2.VideoCapture(0)
camera_video.set(3, 1280)
camera_video.set(4, 960)

# ì–‘ì†
# ì™¼ìª½ ê°€ê¸° ë©ˆì¶”ê¸° ì™¼ìª½ ì í”„
# <--       ì£¼ë¨¹    ì™¼ì† í•˜ì´íŒŒì´ë¸Œ
# ì˜¤ë¥¸ìª½ ê°€ê¸° ë©ˆì¶”ê¸° ì˜¤ë¥¸ìª½ ì í”„
# ->          ì£¼ë¨¹     ì˜¤ë¥¸ì† í•˜ì´íŒŒì´ë¸Œ

# Create named window for resizing purposes.
#cv2.namedWindow('test_finger ', cv2.WINDOW_NORMAL)

# Read the filter image with its blue, green, red, and alpha channel.
filter_imageBGRA = cv2.imread('media/filter.png', cv2.IMREAD_UNCHANGED)

# Initialize a variable to store the status of the filter (i.e., whether to apply the filter or not).
filter_on = False

# Initialize the number of consecutive frames on which we want to check the hand gestures before triggering the events.
num_of_frames = 5

# Initialize a dictionary to store the counts of the consecutive frames with the hand gestures recognized.
counter = {'RIGHT_V_SIGN': 0, 'LEFT_V_SIGN': 0, 'RIGHT_SPIDERMAN_SIGN': 0, 'LEFT_SPIDERMAN_SIGN': 0, 'LEFT_HIGH_FIVE_SIGN': 0, 'RIGHT_HIGH_FIVE_SIGN': 0,
           'RIGHT_STOP_SIGN': 0, 'LEFT_STOP_SIGN': 0}

# Initialize a variable to store the captured image.
captured_image = None

# Iterate until the webcam is accessed successfully.
while camera_video.isOpened():

    # Read a frame.
    ok, frame = camera_video.read()

    # Check if frame is not read properly then continue to the next iteration to read the next frame.
    if not ok:
        continue

    # Flip the frame horizontally for natural (selfie-view) visualization.
    frame = cv2.flip(frame, 1)

    # Get the height and width of the frame of the webcam video.
    frame_height, frame_width, _ = frame.shape

    # Resize the filter image to the size of the frame.
    filter_imageBGRA = cv2.resize(
        filter_imageBGRA, (frame_width, frame_height))

    # Get the three-channel (BGR) image version of the filter image.
    filter_imageBGR = filter_imageBGRA[:, :, :-1]

    # Perform Hands landmarks detection on the frame.
    frame, results = detectHandsLandmarks(
        frame, hands_videos, draw=False, display=False)

    # Check if the hands landmarks in the frame are detected.
    if results.multi_hand_landmarks:

        # Count the number of fingers up of each hand in the frame.
        frame, fingers_statuses, count = countFingers(
            frame, results, draw=False, display=False)

        # Perform the hand gesture recognition on the hands in the frame.
        _, hands_gestures = recognizeGestures(
            frame, fingers_statuses, count, draw=False, display=False)

        # ì™¼ì† í•˜ì´íŒŒì´ë¸Œ
        ####################################################################################################################
        if any(hand_gesture == "LEFT_HIGH_FIVE_SIGN" for hand_gesture in hands_gestures.values()):

            # Increment the count of consecutive frames with SPIDERMAN hand gesture recognized.
            counter['LEFT_HIGH_FIVE_SIGN'] += 1

            # Check if the counter is equal to the required number of consecutive frames.
            if counter['LEFT_HIGH_FIVE_SIGN'] == num_of_frames:

                # Turn on the filter by updating the value of the filter status variable to true.
                filter_on = True

                # Update the counter value to zero.
                counter['LEFT_HIGH_FIVE_SIGN'] = 0

        # Otherwise if the gesture of any hand in the frame is not SPIDERMAN SIGN.
        else:

            # Update the counter value to zero. As we are counting the consective frames with SPIDERMAN hand gesture.
            counter['LEFT_HIGH_FIVE_SIGN'] = 0

        ####################################################################################################################

        # ì˜¤ë¥¸ì† í•˜ì´íŒŒì´ë¸Œ
        ####################################################################################################################
        if any(hand_gesture == "RIGHT_HIGH_FIVE_SIGN" for hand_gesture in hands_gestures.values()):

            # Increment the count of consecutive frames with SPIDERMAN hand gesture recognized.
            counter['RIGHT_HIGH_FIVE_SIGN'] += 1

            # Check if the counter is equal to the required number of consecutive frames.
            if counter['RIGHT_HIGH_FIVE_SIGN'] == num_of_frames:

                # Turn on the filter by updating the value of the filter status variable to true.
                filter_on = True

                # Update the counter value to zero.
                counter['RIGHT_HIGH_FIVE_SIGN'] = 0

        # Otherwise if the gesture of any hand in the frame is not SPIDERMAN SIGN.
        else:

            # Update the counter value to zero. As we are counting the consective frames with SPIDERMAN hand gesture.
            counter['RIGHT_HIGH_FIVE_SIGN'] = 0

        ####################################################################################################################

        # Check if any hand is making the HIGH-FIVE hand gesture in the required number of consecutive frames.
        ####################################################################################################################

#         # Check if the gesture of any hand in the frame is HIGH-FIVE SIGN.
#         if any(hand_gesture == "HIGH-FIVE SIGN" for hand_gesture in hands_gestures.values()):

#             # Increment the count of consecutive frames with HIGH-FIVE hand gesture recognized.
#             counter['HIGH-FIVE SIGN'] += 1

#             # Check if the counter is equal to the required number of consecutive frames.
#             if counter['HIGH-FIVE SIGN'] == num_of_frames:

#                 # Turn off the filter by updating the value of the filter status variable to False.
#                 filter_on = False

#                 # Update the counter value to zero.
#                 counter['HIGH-FIVE SIGN'] = 0

#         # Otherwise if the gesture of any hand in the frame is not HIGH-FIVE SIGN.
#         else:

#             # Update the counter value to zero. As we are counting the consective frames with HIGH-FIVE hand gesture.
#             counter['HIGH-FIVE SIGN'] = 0

        ####################################################################################################################

         # Check if any hand is making the HIGH-FIVE hand gesture in the required number of consecutive frames.
        ####################################################################################################################

        # Check if the gesture of any hand in the frame is HIGH-FIVE SIGN.
        # ì™¼ì† ìŠ¤íƒ‘ ì‚¬ì¸
        ####################################################################################################################
        if any(hand_gesture == "LEFT_STOP_SIGN" for hand_gesture in hands_gestures.values()):

            # Increment the count of consecutive frames with HIGH-FIVE hand gesture recognized.
            counter['LEFT_STOP_SIGN'] += 1

            # Check if the counter is equal to the required number of consecutive frames.
            if counter['LEFT_STOP_SIGN'] == num_of_frames:

                # Turn off the filter by updating the value of the filter status variable to False.
                filter_on = False

                # Update the counter value to zero.
                counter['LEFT_STOP_SIGN'] = 0

        # Otherwise if the gesture of any hand in the frame is not HIGH-FIVE SIGN.
        else:

            # Update the counter value to zero. As we are counting the consective frames with HIGH-FIVE hand gesture.
            counter['LEFT_STOP_SIGN'] = 0

        ####################################################################################################################

        # ì˜¤ë¥¸ì† ìŠ¤íƒ‘ ì‚¬ì¸
        ####################################################################################################################
        if any(hand_gesture == "RIGHT_STOP_SIGN" for hand_gesture in hands_gestures.values()):

            # Increment the count of consecutive frames with HIGH-FIVE hand gesture recognized.
            counter['RIGHT_STOP_SIGN'] += 1

            # Check if the counter is equal to the required number of consecutive frames.
            if counter['RIGHT_STOP_SIGN'] == num_of_frames:

                # Turn off the filter by updating the value of the filter status variable to False.
                filter_on = False

                # Update the counter value to zero.
                counter['RIGHT_STOP_SIGN'] = 0

        # Otherwise if the gesture of any hand in the frame is not HIGH-FIVE SIGN.
        else:

            # Update the counter value to zero. As we are counting the consective frames with HIGH-FIVE hand gesture.
            counter['RIGHT_STOP_SIGN'] = 0

        ####################################################################################################################

    # Check if the filter is turned on.
    if filter_on:

        # Apply the filter by updating the pixel values of the frame at the indexes where the
        # alpha channel of the filter image has the value 255.
        frame[filter_imageBGRA[:, :, -1] ==
              255] = filter_imageBGR[filter_imageBGRA[:, :, -1] == 255]

        ####################################################################################################################

    # Image Capture Functionality.
    ########################################################################################################################

    # Check if the hands landmarks are detected and the gesture of any hand in the frame is V SIGN.

    # ì™¼ì† v ì‚¬ì¸
    ####################################################################################################################

    if results.multi_hand_landmarks and any(hand_gesture == "LEFT_V_SIGN" for hand_gesture in hands_gestures.values()):

        # Increment the count of consecutive frames with V hand gesture recognized.
        counter['LEFT_V_SIGN'] += 1

        # Check if the counter is equal to the required number of consecutive frames.
        if counter['LEFT_V_SIGN'] == num_of_frames:

            # Make a border around a copy of the current frame.
            captured_image = cv2.copyMakeBorder(src=frame, top=10, bottom=10, left=10, right=10,
                                                borderType=cv2.BORDER_CONSTANT, value=(255, 255, 255))

            # Capture an image and store it in the disk.
            cv2.imwrite('Captured_Image.png', captured_image)

            # Display a black image.
            cv2.imshow('Selfie-Capturing System',
                       np.zeros((frame_height, frame_width)))

            # Play the image capture music to indicate the an image is captured and wait for 100 milliseconds.
            cv2.waitKey(100)

            # Display the captured image.
            plt.close()
            plt.figure(figsize=[10, 10])
            plt.imshow(frame[:, :, ::-1])
            plt.title("Captured Image")
            plt.axis('off')

            # Update the counter value to zero.
            counter['LEFT_V_SIGN'] = 0

    # Otherwise if the gesture of any hand in the frame is not V SIGN.
    else:

        # Update the counter value to zero. As we are counting the consective frames with V hand gesture.
        counter['LEFT_V_SIGN'] = 0

    ########################################################################################################################

      # ì˜¤ë¥¸ì† v ì‚¬ì¸
    ####################################################################################################################

    if results.multi_hand_landmarks and any(hand_gesture == "RIGHT_V_SIGN" for hand_gesture in hands_gestures.values()):

        # Increment the count of consecutive frames with V hand gesture recognized.
        counter['RIGHT_V_SIGN'] += 1

        # Check if the counter is equal to the required number of consecutive frames.
        if counter['RIGHT_V_SIGN'] == num_of_frames:

            # Make a border around a copy of the current frame.
            captured_image = cv2.copyMakeBorder(src=frame, top=10, bottom=10, left=10, right=10,
                                                borderType=cv2.BORDER_CONSTANT, value=(255, 255, 255))

            # Capture an image and store it in the disk.
            cv2.imwrite('Captured_Image.png', captured_image)

            # Display a black image.
            cv2.imshow('Selfie-Capturing System',
                       np.zeros((frame_height, frame_width)))

            # Play the image capture music to indicate the an image is captured and wait for 100 milliseconds.
            cv2.waitKey(100)

            # Display the captured image.
            plt.close()
            plt.figure(figsize=[10, 10])
            plt.imshow(frame[:, :, ::-1])
            plt.title("Captured Image")
            plt.axis('off')

            # Update the counter value to zero.
            counter['RIGHT_V_SIGN'] = 0

    # Otherwise if the gesture of any hand in the frame is not V SIGN.
    else:

        # Update the counter value to zero. As we are counting the consective frames with V hand gesture.
        counter['RIGHT_V_SIGN'] = 0

    ########################################################################################################################

    # Check if we have captured an image.
    if captured_image is not None:

        # Resize the image to the 1/5th of its current width while keeping the aspect ratio constant.
        captured_image = cv2.resize(
            captured_image, (frame_width//5, int(((frame_width//5) / frame_width) * frame_height)))

        # Get the new height and width of the image.
        img_height, img_width, _ = captured_image.shape

        # Overlay the resized captured image over the frame by updating its pixel values in the region of interest.
        frame[10: 10+img_height, 10: 10+img_width] = captured_image

    # Display the frame.
    cv2.imshow('Selfie-Capturing System', frame)

    # Wait for 1ms. If a key is pressed, retreive the ASCII code of the key.
    k = cv2.waitKey(1) & 0xFF

    # Check if 'ESC' is pressed and break the loop.
    if(k == 27):
        break

# Release the VideoCapture Object and close the windows.
camera_video.release()
cv2.destroyAllWindows()
